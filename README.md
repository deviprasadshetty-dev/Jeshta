# Jeshta (à¤œà¥à¤¯à¥‡à¤·à¥à¤ à¤¾)

<p align="center">
  <img src="./image.png" width="200" alt="Jeshta - AI Memory" style="border-radius: 50%;">
</p>

> *"I hold your memories so they never fade away~"* â€” **Jeshta** âœ¨

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/downloads/)
[![MCP Ready](https://img.shields.io/badge/MCP-Ready-green.svg)](https://github.com/modelcontextprotocol)

> **Persistent, intelligent memory for Agentic AI.**

**Jeshta** is a local-first MCP server that gives LLMs true long-term memory. Featuring custom algorithms for binary quantization, spreading activation, topological delta resolution, and Ebbinghaus-inspired forgetting curves â€” all without heavy dependencies.

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| ğŸ§  **Multi-Scope Memory** | Global preferences persist across ALL projects; project memories stay isolated |
| ğŸ”„ **Forgetting Curve** | Ebbinghaus-inspired decay â€” unused memories fade, accessed ones strengthen |
| ğŸŒ **Spreading Activation** | Search for "Login" also activates "Authentication" and "Sessions" |
| ğŸ“Š **Hierarchical Search** | Project scope first, global fallback â€” with priority weighting |
| ğŸ›¡ï¸ **Causal Integrity** | Detects temporal paradoxes and graph corruption |
| âœ¨ **Dreaming** | Consolidates similar memories into optimized archetypes |
| ğŸ”Œ **Zero Dependencies** | Just Python + NumPy. Local-first, no cloud required |

## ğŸ› ï¸ 6 Essential Tools

Jeshta exposes only what you need â€” no bloat:

| Tool | Purpose |
|------|---------|
| `add_atom` | Save a memory (auto-detects global vs project) |
| `search_atoms` | Recall memories (hierarchical: project â†’ global) |
| `compile_context` | Initialize session with merged context |
| `delete_atom` | Explicitly forget something |
| `recall_related` | Explore memory relationships |
| `verify_integrity` | Self-check for paradoxes |

## ğŸ—ï¸ Architecture

```mermaid
flowchart LR
    subgraph Client
        Input[New Memory]
        Query[Context Request]
    end

    subgraph "Jeshta Server"
        direction TB
        Ingest[add_atom] --> Scope{Global?}
        Scope -->|Yes| Global[(Global DB)]
        Scope -->|No| Project[(Project DB)]
        
        Search[search_atoms] --> Hierarchical[Project â†’ Global]
        Hierarchical --> Activation[Spreading Activation]
        Activation --> Ranked[Ranked Results]
    end

    Input --> Ingest
    Query --> Search
    Ranked --> Client
```

## ğŸš€ Quick Start

### Installation
```bash
pip install numpy fastembed
```

### Running
```bash
python server.py
```

### Integration (Claude Desktop)
Add to `%APPDATA%\Claude\claude_desktop_config.json`:
```json
{
  "mcpServers": {
    "jeshta": {
      "command": "python",
      "args": ["D:\\brain\\buddi\\server.py"]
    }
  }
}
```

## ğŸ§¬ How Memory Works

### Scope Hierarchy
```
User: "I always prefer dark mode"
â†’ Auto-detected as GLOBAL (keyword: "always")
â†’ Persists across ALL projects

User: "This project uses GraphQL"  
â†’ Saved to PROJECT scope
â†’ Only available in this workspace
```

### Forgetting Curve
```
Retention = e^(-t/S)

t = days since last access
S = stability (grows with access count)

Frequently accessed â†’ Strong retention
Never accessed â†’ Gradually forgotten
```

---

<p align="center">
  <strong>Jeshta</strong> â€” Memory that learns, forgets, and remembers what matters.
  <br>
  Built with â¤ï¸ for the Agentic Future.
</p>
